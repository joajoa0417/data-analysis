{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccc42ea",
   "metadata": {},
   "source": [
    "### **ğŸ§  ë¨¸ì‹ ëŸ¬ë‹ ì‹¤ìŠµ - ì´ì§„ ë¶„ë¥˜**\n",
    "#### Q1. í™˜ìì˜ ë‹¹ë‡¨ë³‘ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `diabetes_train.csv`, `diabetes_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `Outcome` (0: ì •ìƒ, 1: ë‹¹ë‡¨ë³‘)\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ í™˜ìì˜ ë‹¹ë‡¨ë³‘ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’ (ë‹¹ë‡¨ë³‘ì¼ í™•ë¥ )\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ROC-AUC í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10eb69e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: 0.8234969663541093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(154, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "train = pd.read_csv('diabetes_train.csv')\n",
    "test = pd.read_csv('diabetes_test.csv')\n",
    "\n",
    "## EDA\n",
    "# print(train.shape, test.shape) # ((614, 9), (154, 8))\n",
    "# train.info() # not object\n",
    "# test.info()\n",
    "# train.describe()\n",
    "# print(train.isnull().sum())\n",
    "# print(test.isnull().sum())\n",
    "# print(train['Outcome'].value_counts()) # 0: 403 / 1: 211\n",
    "\n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "y_train = train.pop('Outcome')\n",
    "## - ìŠ¤ì¼€ì¼ë§\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "train = minmax.fit_transform(train)\n",
    "test = minmax.transform(test)\n",
    "\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=42)\n",
    "# print(X_train.shape, X_val.shape, y_train.shape, y_val.shape) # (491, 8) (123, 8) (491,) (123,)\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "rf = RandomForestClassifier(max_depth=5, n_estimators=500, random_state=0)\n",
    "# rf = RandomForestClassifier(random_state=0) # ê¸°ë³¸\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict_proba(X_val)\n",
    "# print(rf.classes_)\n",
    "# print(pred)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, pred[:,1])\n",
    "print('roc_auc:', roc_auc)\n",
    "\n",
    "## ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±\n",
    "pred = rf.predict_proba(test)\n",
    "result = pd.DataFrame({'pred':pred[:,1]})\n",
    "result.to_csv('new.csv', index=False)\n",
    "\n",
    "pd.read_csv('new.csv').shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa0f6a8",
   "metadata": {},
   "source": [
    "ìŠ¤ì¼€ì¼ë§ ì „ roc_auc : 0.8167402095973524\n",
    "\n",
    "\n",
    "\n",
    "ìŠ¤ì¼€ì¼ë§ í›„ roc_auc : 0.8234969663541093\n",
    "\n",
    "\n",
    "**[í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹]**\n",
    "- `max_depth` : íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´, ê³¼ì í•© ë°©ì§€, 3~7 ì •ë„ ì ë‹¹\n",
    "- `n_estimators` : íŠ¸ë¦¬ì˜ ê°œìˆ˜, ë†’ì„ìˆ˜ë¡ ì•ˆì •ì  ì˜ˆì¸¡ ê°€ëŠ¥(í•™ìŠµ ì‹œê°„ ì†Œìš”), 200~500 ì •ë„ ì ë‹¹\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc35ca7",
   "metadata": {},
   "source": [
    "#### Q2. ìƒˆë¡œìš´ ì¼ìë¦¬ë¥¼ ì°¾ì„ì§€ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `hr_train.csv`, `hr_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `target` (0: ìƒˆë¡œìš´ ì¼ìë¦¬ë¥¼ ì°¾ì§€ ì•ŠìŒ, 1: ìƒˆë¡œìš´ ì¼ìë¦¬ë¥¼ ì°¾ìŒ)\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ ìƒˆ ì¼ìë¦¬ë¥¼ ì°¾ì„ì§€ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’ (ì´ì§í•  í™•ë¥ )\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new2.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ROC-AUC í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8860c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc: 0.7952435945564116\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.394253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.157046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred\n",
       "0  0.234171\n",
       "1  0.394253\n",
       "2  0.411359\n",
       "3  0.140237\n",
       "4  0.157046"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('hr_train.csv')\n",
    "test = pd.read_csv('hr_test.csv')\n",
    "\n",
    "## EDA\n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "# print(train.isnull().sum()) # gender, enrolled_university, education_level, major_discipline, experience, company_size, company_type, last_new_job\n",
    "# print(test.isnull().sum())\n",
    "# train.describe()\n",
    "# train.describe(include='O')\n",
    "# test.describe(include='O')\n",
    "# train['target'].value_counts() # 0.0: 11517 / 1.0: 3809\n",
    "# print(train.shape, test.shape) # (15326, 14) (3832, 13)\n",
    "\n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# train = train.drop('enrollee_id', axis=1)\n",
    "# test = test.drop('enrollee_id', axis=1)\n",
    "\n",
    "train = train.fillna('X')\n",
    "test = test.fillna('X')\n",
    "\n",
    "# print(train.isnull().sum().sum(), test.isnull().sum().sum())\n",
    "\n",
    "y_train = train.pop('target')\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "# train.shape, test.shape # ë¶ˆì¼ì¹˜\n",
    "\n",
    "df = pd.concat([train, test], axis=0)\n",
    "df_oh = pd.get_dummies(df)\n",
    "train = df_oh.iloc[:len(train)].copy()\n",
    "test = df_oh.iloc[len(train):].copy()\n",
    "\n",
    "# train.shape, test.shape # ì¼ì¹˜\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”©\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "\n",
    "for col in cols_obj :\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "train = df[:len(train)].copy()\n",
    "test = df[len(train):].copy()\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_num = train.select_dtypes(exclude='O').columns\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "train[cols_num] = minmax.fit_transform(train[cols_num])\n",
    "test[cols_num] = minmax.transform(test[cols_num])\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,\n",
    "                                                  y_train,\n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42)\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=5, n_estimators=500)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict_proba(X_val)\n",
    "\n",
    "# print(rf.classes_)\n",
    "# print(y_pred)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred[:,1])\n",
    "print('roc-auc:', roc_auc)\n",
    "\n",
    "## ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±\n",
    "pred = rf.predict_proba(test)\n",
    "result = pd.DataFrame({'pred':pred[:,1]})\n",
    "result.to_csv('new2.csv', index=False)\n",
    "\n",
    "pd.read_csv('new2.csv').head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.select_dtypes(include='O')\n",
    "\n",
    "for col in cols:\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "\n",
    "    if train_set == test_set :\n",
    "        print(col, 'ë™ì¼')\n",
    "    else :\n",
    "        print(col, 'ë™ì¼í•˜ì§€ ì•ŠìŒ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f0971",
   "metadata": {},
   "source": [
    "---\n",
    "#### Q3. ì‹ ìš©ì¹´ë“œ ì‹ ì²­ìì˜ ì±„ë¬´ ë¶ˆì´í–‰ì„ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `creditcard_train.csv`, `creditcard_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `STATUS` (0: ì±„ë¬´ ì´í–‰, 1: ì±„ë¬´ ë¶ˆì´í–‰)\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ ë¯¸ë˜ì˜ ì±„ë¬´ ë¶ˆì´í–‰ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’ (ì±„ë¬´ ë¶ˆì´í–‰ í™•ë¥ )\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new3.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ F1 í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d253b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE_GENDER ë™ì¼\n",
      "FLAG_OWN_CAR ë™ì¼\n",
      "FLAG_OWN_REALTY ë™ì¼\n",
      "NAME_INCOME_TYPE ë™ì¼\n",
      "NAME_EDUCATION_TYPE ë™ì¼\n",
      "NAME_FAMILY_STATUS ë™ì¼\n",
      "NAME_HOUSING_TYPE ë™ì¼\n",
      "OCCUPATION_TYPE ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "-----------------------\n",
      "[0 1]\n",
      "[0 0 0 ... 0 0 0]\n",
      "f1-score: 0.3241106719367589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7591, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('creditcard_train.csv')\n",
    "test = pd.read_csv('creditcard_test.csv')\n",
    "\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "\n",
    "    if train_set == test_set :\n",
    "        print(col, 'ë™ì¼')\n",
    "    else :\n",
    "        print(col, 'ë™ì¼í•˜ì§€ ì•ŠìŒ')\n",
    "\n",
    "print('-----------------------')\n",
    "\n",
    "## EDA\n",
    "# train.info()\n",
    "# test.info()\n",
    "# train.shape, test.shape # ((25519, 19), (7591, 18))\n",
    "# train.isnull().sum() # OCCUPATION_TYPE \n",
    "# test.isnull().sum()\n",
    "# train['STATUS'].value_counts() # 0: 25085 / 1: 434\n",
    "\n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# train['OCCUPATION_TYPE'].value_counts()\n",
    "train['OCCUPATION_TYPE'] = train['OCCUPATION_TYPE'].fillna(train['OCCUPATION_TYPE'].mode()[0])\n",
    "\n",
    "train = train.drop('ID', axis=1)\n",
    "test = test.drop('ID', axis=1)\n",
    "\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "\n",
    "y_train = train.pop('STATUS')\n",
    "\n",
    "# # ì›-í•« ì¸ì½”ë”©\n",
    "# train = pd.get_dummies(train)\n",
    "# test = pd.get_dummies(test)\n",
    "# # train.shape, test.shape\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”©\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in cols_obj :\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "    \n",
    "# # ìŠ¤ì¼€ì¼ë§ (ê°œì„  x)\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# cols_num = train.select_dtypes(exclude='O').columns\n",
    "\n",
    "# minmax = MinMaxScaler()\n",
    "# train[cols_num] = minmax.fit_transform(train[cols_num])\n",
    "# test[cols_num] = minmax.transform(test[cols_num])\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë¶„í• \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, \n",
    "                                                  y_train, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=0)\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, n_estimators=500, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "print(rf.classes_)\n",
    "print(y_pred)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print('f1-score:', f1)\n",
    "\n",
    "## ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred})\n",
    "result.to_csv('new3.csv', index=False)\n",
    "\n",
    "pd.read_csv('new3.csv').shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786008c",
   "metadata": {},
   "source": [
    "---\n",
    "### **ğŸ§  ë¨¸ì‹ ëŸ¬ë‹ ì‹¤ìŠµ - ë‹¤ì¤‘ ë¶„ë¥˜**\n",
    "#### Q1. ì€í–‰ ì •ë³´ë¡œ ì‹ ìš© ë“±ê¸‰ì„ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `score_train.csv`, `score_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `Credit_Score` (Good, Standard, Poor)\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ ì‹ ìš© ë“±ê¸‰ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new4.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ F1-macro í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85117751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payment_of_Min_Amount ë™ì¼\n",
      "Credit_Mix ë™ì¼\n",
      "Payment_Behaviour ë™ì¼\n",
      "---------------------\n",
      "['Good' 'Poor' 'Standard']\n",
      "---------------------\n",
      "f1-macro: 0.7006138262986147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1499, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('score_train.csv')\n",
    "test = pd.read_csv('score_test.csv')\n",
    "\n",
    "## EDA\n",
    "# train.head()\n",
    "# train.info()\n",
    "# test.info()\n",
    "# train.isnull().sum()\n",
    "# test.isnull().sum()\n",
    "# print(train.shape, test.shape)\n",
    "# train['Credit_Score'].value_counts()\n",
    "\n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "y_train = train.pop('Credit_Score')\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[cols_obj])\n",
    "    test_set = set(test[cols_obj])\n",
    "    \n",
    "    if train_set == test_set :\n",
    "        print(col, 'ë™ì¼')\n",
    "    else :\n",
    "        print(col, 'ë™ì¼í•˜ì§€ ì•ŠìŒ')\n",
    "print('---------------------')\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "train.shape, test.shape\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_num = train.select_dtypes(exclude='O').columns\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "train[cols_num] = minmax.fit_transform(train[cols_num])\n",
    "test[cols_num] = minmax.transform(test[cols_num])\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, \n",
    "                                                  y_train, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=0)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "print(rf.classes_)\n",
    "print('---------------------')\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_val, y_pred, average='macro')\n",
    "print('f1-macro:', f1)\n",
    "\n",
    "## ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred})\n",
    "result.to_csv('new4.csv', index=False)\n",
    "\n",
    "pd.read_csv('new4.csv').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedabdf9",
   "metadata": {},
   "source": [
    "#### Q2. ì£¼ì–´ì§„ ë°ì´í„°ì—ì„œ ì•½ë¬¼ì˜ ì¢…ë¥˜ë¥¼ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `drug_train.csv`, `drug_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `Drug` (DrugY, DrugX, drugA, drugC, drugB)\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ ì•½ë¬¼ì˜ ì¢…ë¥˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new5.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ f1-macro í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3419fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex ë™ì¼\n",
      "BP ë™ì¼\n",
      "Cholesterol ë™ì¼\n",
      "---------------------------\n",
      "---------------------------\n",
      "f1: 0.9074643874643874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('drug_train.csv')\n",
    "test = pd.read_csv('drug_test.csv')\n",
    "\n",
    "## EDA\n",
    "train.head()\n",
    "train.shape, test.shape # ((100, 6), (100, 5))\n",
    "train.isnull().sum()\n",
    "test.isnull().sum()\n",
    "train.describe()\n",
    "train.describe(include='O')\n",
    "\n",
    "y_train = train.pop('Drug')\n",
    "\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "cols_num = train.select_dtypes(exclude='O').columns\n",
    "\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "    if train_set == test_set :\n",
    "        print(col, 'ë™ì¼')\n",
    "    else :\n",
    "        print(col, 'ë™ì¼í•˜ì§€ ì•ŠìŒ')\n",
    "\n",
    "print('---------------------------')\n",
    "\n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "train.shape, test.shape\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”©\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for col in cols_obj : \n",
    "#     le = LabelEncoder()\n",
    "#     train[col] = le.fit_transform(train[col])\n",
    "#     test[col] = le.transform(test[col])\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "## í¬ë¡œìŠ¤ ë°¸ë¦¬ë°ì´ì…˜ í™œìš©\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "# rf.fit(X_train, y_train)\n",
    "# y_pred = rf.predict(X_val)\n",
    "# print(rf.classes_)\n",
    "# print(y_pred)\n",
    "print('---------------------------')\n",
    "\n",
    "f1 = cross_val_score(rf, train, y_train, cv=3, scoring='f1_macro')\n",
    "print('f1:', f1.mean())\n",
    "\n",
    "## ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±\n",
    "rf.fit(train, y_train)\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred})\n",
    "result.to_csv('new5.csv', index=False)\n",
    "\n",
    "pd.read_csv('new5.csv').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a6d81",
   "metadata": {},
   "source": [
    "#### Q3. ì£¼ì–´ì§„ ë°ì´í„°ì—ì„œ ìœ ë¦¬ì˜ ì¢…ë¥˜ë¥¼ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `glass_train.csv`, `glass_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `Type` (1, 2, 3, 4, 5, 6, 7)\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ ìœ ë¦¬ì˜ ì¢…ë¥˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new6.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ f1-weighted í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc20eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.6507936507936507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(65, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('glass_train.csv')\n",
    "test = pd.read_csv('glass_test.csv')\n",
    "\n",
    "## EDA\n",
    "# train.shape, test.shape # ((149, 10), (65, 9))\n",
    "# train.info()\n",
    "# test.info()\n",
    "# train.isnull().sum()  \n",
    "# test.isnull().sum()\n",
    "# train['Type'].value_counts()\n",
    "# train.describe()\n",
    "\n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "y_train = train.pop('Type')\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "# train.shape, test.shape\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”©\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# df = pd.concat([train, test])\n",
    "\n",
    "# cols = train.columns\n",
    "# for col in cols :\n",
    "#     le = LabelEncoder()\n",
    "#     df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# train = df.iloc[:len(train)]\n",
    "# test = df.iloc[len(train):]\n",
    "\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=5, n_estimators=700)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "# print(rf.classes_)\n",
    "# print(y_pred)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "print('f1:', f1)\n",
    "\n",
    "## ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±í•˜ê¸°\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred})\n",
    "result.to_csv('new6.csv', index=False)\n",
    "\n",
    "pd.read_csv('new6.csv').shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda6db6f",
   "metadata": {},
   "source": [
    "---\n",
    "### **ğŸ§  ë¨¸ì‹ ëŸ¬ë‹ ì‹¤ìŠµ - íšŒê·€**\n",
    "#### Q1. í•­ê³µê¶Œ í‹°ì¼“ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `flight_train.csv`, `flight_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `price`\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ í‹°ì¼“ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’ (ê°€ê²©)\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new7.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ RMSE í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b22eeca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ ì¹´í…Œê³ ë¦¬ ë™ì¼ ì—¬ë¶€ ------\n",
      "airline ë™ì¼\n",
      "flight ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "source_city ë™ì¼\n",
      "departure_time ë™ì¼\n",
      "stops ë™ì¼\n",
      "arrival_time ë™ì¼\n",
      "destination_city ë™ì¼\n",
      "class ë™ì¼\n",
      "\n",
      "------ RMSE SCORE ------\n",
      "rmse: 3674.8958942154045\n",
      "\n",
      "------ ìµœì¢… ê²°ê³¼ íŒŒì¼ í™•ì¸ ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4502, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('flight_train.csv')\n",
    "test = pd.read_csv('flight_test.csv')\n",
    "\n",
    "## EDA\n",
    "# train.info()\n",
    "# test.info()\n",
    "# print(train.shape, test.shape) # (10505, 11) (4502, 10)\n",
    "# train.describe()\n",
    "# train.describe(include='O')\n",
    "# train.isnull().sum()\n",
    "# test.isnull().sum()\n",
    "\n",
    "print ('------ ì¹´í…Œê³ ë¦¬ ë™ì¼ ì—¬ë¶€ ------')\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "    if train_set == test_set :\n",
    "        print(col, 'ë™ì¼')\n",
    "    else :\n",
    "        print(col, 'ë™ì¼í•˜ì§€ ì•ŠìŒ')\n",
    "        \n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "y_train = train.pop('price')\n",
    "\n",
    "train['new_flight'] = train['flight'].str.split('-').str[1].astype(int)\n",
    "test['new_flight'] = test['flight'].str.split('-').str[1].astype(int)\n",
    "\n",
    "train = train.drop('flight', axis=1)\n",
    "test = test.drop('flight', axis=1)\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "# print(train.shape, train_oh.shape, test.shape, test_oh.shape)\n",
    "\n",
    "# df = pd.concat([train, test], axis=0)\n",
    "# df = pd.get_dummies(df)\n",
    "# train = df[:len(train)]\n",
    "# test = df[len(train):]\n",
    "# train.shape, test.shape\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cols_num = train.select_dtypes(exclude='O').columns\n",
    "rb = StandardScaler()\n",
    "train[cols_num] = rb.fit_transform(train[cols_num])\n",
    "test[cols_num] = rb.transform(test[cols_num])\n",
    "\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=0)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, max_depth=20, n_estimators=200)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "rmse = root_mean_squared_error(y_val, y_pred)\n",
    "print ('\\n------ RMSE SCORE ------')\n",
    "print('rmse:', rmse)  \n",
    "\n",
    "## ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred}).to_csv('new7.csv', index=False)\n",
    "\n",
    "print ('\\n------ ìµœì¢… ê²°ê³¼ íŒŒì¼ í™•ì¸ ------')\n",
    "pd.read_csv('new7.csv').shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75544460",
   "metadata": {},
   "source": [
    "#### Q2. ë…¸íŠ¸ë¶ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `laptop_train.csv`, `laptop_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `Price`\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ ë…¸íŠ¸ë¶ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’ (ê°€ê²©)\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new8.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ RÂ²(ê²°ì •ê³„ìˆ˜) í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6dcab750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 91 entries, 0 to 90\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Brand               91 non-null     object \n",
      " 1   Model               82 non-null     object \n",
      " 2   Series              55 non-null     object \n",
      " 3   Processor           86 non-null     object \n",
      " 4   Processor_Gen       86 non-null     object \n",
      " 5   RAM                 85 non-null     float64\n",
      " 6   Hard_Disk_Capacity  85 non-null     object \n",
      " 7   OS                  85 non-null     object \n",
      " 8   Rating              91 non-null     float64\n",
      " 9   Price               91 non-null     int64  \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 7.2+ KB\n",
      "------ ì¹´í…Œê³ ë¦¬ ë™ì¼ ì—¬ë¶€ ------\n",
      "Brand ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "Processor ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "Processor_Gen ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "Hard_Disk_Capacity ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "OS ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "\n",
      "------ RÂ² SCORE ------\n",
      "RÂ²: 0.8059084005677305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joajo\\AppData\\Local\\Temp\\ipykernel_4168\\2304860439.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[cols_num] = scaler.fit_transform(train[cols_num])\n",
      "C:\\Users\\joajo\\AppData\\Local\\Temp\\ipykernel_4168\\2304860439.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[cols_num] = scaler.transform(test[cols_num])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('laptop_train.csv')\n",
    "test = pd.read_csv('laptop_test.csv')\n",
    "\n",
    "## EDA\n",
    "train.info()\n",
    "train.isnull().sum()\n",
    "test.isnull().sum()\n",
    "\n",
    "train = train.drop('Model', axis=1)\n",
    "test = test.drop('Model', axis=1)\n",
    "train = train.drop('Series', axis=1)\n",
    "test = test.drop('Series', axis=1)\n",
    "\n",
    "print ('------ ì¹´í…Œê³ ë¦¬ ë™ì¼ ì—¬ë¶€ ------')\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "    if train_set == test_set :\n",
    "        print(col, 'ë™ì¼')\n",
    "    else :\n",
    "        print(col, 'ë™ì¼í•˜ì§€ ì•ŠìŒ')\n",
    "        \n",
    "# train.describe()    \n",
    "# train.describe(include='O')\n",
    "\n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "y_train = train.pop('Price')\n",
    "\n",
    "# ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
    "train[cols_obj] = train[cols_obj].fillna('X')\n",
    "test[cols_obj] = test[cols_obj].fillna('X')\n",
    "\n",
    "train['RAM'] = train['RAM'].fillna(train['RAM'].mode()[0])\n",
    "test['RAM'] = test['RAM'].fillna(test['RAM'].mode()[0])\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "# train_oh = pd.get_dummies(train)\n",
    "# test_oh = pd.get_dummies(test)\n",
    "# train.shape, train_oh.shape, test.shape, test_oh.shape\n",
    "df = pd.concat([train, test])\n",
    "df_oh = pd.get_dummies(df)\n",
    "train = df_oh[:len(train)]\n",
    "test = df_oh[len(train):]\n",
    "# train.shape, train_oh.shape, test.shape, test_oh.shape\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cols_num = train.select_dtypes(exclude='O').columns\n",
    "scaler = StandardScaler()\n",
    "train[cols_num] = scaler.fit_transform(train[cols_num])\n",
    "test[cols_num] = scaler.transform(test[cols_num])\n",
    "\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print ('\\n------ RÂ² SCORE ------')\n",
    "print('RÂ²:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e592ee5b",
   "metadata": {},
   "source": [
    "#### Q3. ë…¸íŠ¸ë¶ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `car_train.csv`, `car_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `Price`\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ ì¤‘ê³ ì°¨ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’ (ê°€ê²©)\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new9.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ RMSLE í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a08e8407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ ì¹´í…Œê³ ë¦¬ ë™ì¼ ì—¬ë¶€ ------\n",
      "Levy ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "Manufacturer ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "Model ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "Category ë™ì¼\n",
      "Leather interior ë™ì¼\n",
      "Fuel type ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "Engine volume ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "Mileage ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "Gear box type ë™ì¼\n",
      "Drive wheels ë™ì¼\n",
      "Doors ë™ì¼\n",
      "Wheel ë™ì¼\n",
      "Color ë™ì¼\n",
      "\n",
      "------ RMSLE SCORE ------\n",
      "RMSLE: 1.0822004244243006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40019.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10820.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16399.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69105.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47603.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred\n",
       "0  40019.835\n",
       "1  10820.880\n",
       "2  16399.925\n",
       "3  69105.440\n",
       "4  47603.045"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('car_train.csv')\n",
    "test = pd.read_csv('car_test.csv')\n",
    "\n",
    "## EDA\n",
    "# train.info()\n",
    "# train.isnull().sum()\n",
    "# test.isnull().sum()\n",
    "# train.describe()\n",
    "# train.describe(include='O')\n",
    "# train.shape, test.shape # ((6732, 17), (5772, 16))\n",
    "\n",
    "print ('------ ì¹´í…Œê³ ë¦¬ ë™ì¼ ì—¬ë¶€ ------')\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "    if train_set == test_set :\n",
    "        print(col, 'ë™ì¼')\n",
    "    else :\n",
    "        print(col, 'ë™ì¼í•˜ì§€ ì•ŠìŒ')\n",
    "        \n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "y_train = train.pop('Price')\n",
    "\n",
    "train['Turbo'] = train['Engine volume'].str.contains('Turbo').astype(int)\n",
    "test['Turbo'] = test['Engine volume'].str.contains('Turbo').astype(int)\n",
    "\n",
    "train['Engine volume'] = train['Engine volume'].str.replace('Turbo', '').astype(float)\n",
    "test['Engine volume'] = test['Engine volume'].str.replace('Turbo', '').astype(float)\n",
    "\n",
    "train['Mileage'] = train['Mileage'].str.split().str[0].astype(int)\n",
    "test['Mileage'] = test['Mileage'].str.split().str[0].astype(int)\n",
    "\n",
    "# # ìŠ¤ì¼€ì¼ë§\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# cols_num = train.select_dtypes(exclude='O').columns\n",
    "# scaler = RobustScaler()\n",
    "# train[cols_num] = scaler.fit_transform(train[cols_num])\n",
    "# test[cols_num] = scaler.transform(test[cols_num])\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "# df = pd.concat([train, test])\n",
    "# df_oh = pd.get_dummies(df)\n",
    "# train_oh = df_oh.iloc[:len(train)]\n",
    "# test_oh = df_oh.iloc[len(train):]\n",
    "# print(train.shape, train_oh.shape, test.shape, test_oh.shape)\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”©\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.concat([train, test])\n",
    "for col in cols_obj :\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "train = df.iloc[:len(train)]\n",
    "test = df.iloc[len(train):]\n",
    "    \n",
    "# print(train.shape, test.shape)\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, n_estimators=200)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "rmsle = root_mean_squared_log_error(y_val, y_pred)\n",
    "print ('\\n------ RMSLE SCORE ------')\n",
    "print('RMSLE:', rmsle)\n",
    "\n",
    "# ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred}).to_csv('new9.csv', index=False)\n",
    "pd.read_csv('new9.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6780e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
