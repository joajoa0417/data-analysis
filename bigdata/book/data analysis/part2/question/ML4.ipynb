{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccc42ea",
   "metadata": {},
   "source": [
    "### **ğŸ§  ë¨¸ì‹ ëŸ¬ë‹ ì‹¤ìŠµ - ì´ì§„ ë¶„ë¥˜**\n",
    "#### Q1. í™˜ìì˜ ë‹¹ë‡¨ë³‘ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `diabetes_train.csv`, `diabetese_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `Outcome` (0: ì •ìƒ, 1: ë‹¹ë‡¨ë³‘)\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ í™˜ìì˜ ë‹¹ë‡¨ë³‘ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’ (ë‹¹ë‡¨ë³‘ì¼ í™•ë¥ )\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ROC-AUC í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10eb69e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: 0.8234969663541093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(154, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "train = pd.read_csv('diabetes_train.csv')\n",
    "test = pd.read_csv('diabetes_test.csv')\n",
    "\n",
    "## EDA\n",
    "# print(train.shape, test.shape) # ((614, 9), (154, 8))\n",
    "# train.info() # not object\n",
    "# test.info()\n",
    "# train.describe()\n",
    "# print(train.isnull().sum())\n",
    "# print(test.isnull().sum())\n",
    "# print(train['Outcome'].value_counts()) # 0: 403 / 1: 211\n",
    "\n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "y_train = train.pop('Outcome')\n",
    "## - ìŠ¤ì¼€ì¼ë§\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "train = minmax.fit_transform(train)\n",
    "test = minmax.transform(test)\n",
    "\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=42)\n",
    "# print(X_train.shape, X_val.shape, y_train.shape, y_val.shape) # (491, 8) (123, 8) (491,) (123,)\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "rf = RandomForestClassifier(max_depth=5, n_estimators=500, random_state=0)\n",
    "# rf = RandomForestClassifier(random_state=0) # ê¸°ë³¸\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict_proba(X_val)\n",
    "# print(rf.classes_)\n",
    "# print(pred)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, pred[:,1])\n",
    "print('roc_auc:', roc_auc)\n",
    "\n",
    "## ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±\n",
    "pred = rf.predict_proba(test)\n",
    "result = pd.DataFrame({'pred':pred[:,1]})\n",
    "result.to_csv('new.csv', index=False)\n",
    "\n",
    "pd.read_csv('new.csv').shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa0f6a8",
   "metadata": {},
   "source": [
    "ìŠ¤ì¼€ì¼ë§ ì „ roc_auc : 0.8167402095973524\n",
    "\n",
    "\n",
    "\n",
    "ìŠ¤ì¼€ì¼ë§ í›„ roc_auc : 0.8234969663541093\n",
    "\n",
    "\n",
    "**[í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹]**\n",
    "- `max_depth` : íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´, ê³¼ì í•© ë°©ì§€, 3~7 ì •ë„ ì ë‹¹\n",
    "- `n_estimators` : íŠ¸ë¦¬ì˜ ê°œìˆ˜, ë†’ì„ìˆ˜ë¡ ì•ˆì •ì  ì˜ˆì¸¡ ê°€ëŠ¥(í•™ìŠµ ì‹œê°„ ì†Œìš”), 200~500 ì •ë„ ì ë‹¹\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc35ca7",
   "metadata": {},
   "source": [
    "#### Q2. ìƒˆë¡œìš´ ì¼ìë¦¬ë¥¼ ì°¾ì„ì§€ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `hr_train.csv`, `hr_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `target` (0: ìƒˆë¡œìš´ ì¼ìë¦¬ë¥¼ ì°¾ì§€ ì•ŠìŒ, 1: ìƒˆë¡œìš´ ì¼ìë¦¬ë¥¼ ì°¾ìŒ)\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ ìƒˆ ì¼ìë¦¬ë¥¼ ì°¾ì„ì§€ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’ (ì´ì§í•  í™•ë¥ )\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new2.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ROC-AUC í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8860c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc: 0.7952435945564116\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.394253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.157046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred\n",
       "0  0.234171\n",
       "1  0.394253\n",
       "2  0.411359\n",
       "3  0.140237\n",
       "4  0.157046"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('hr_train.csv')\n",
    "test = pd.read_csv('hr_test.csv')\n",
    "\n",
    "## EDA\n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "# print(train.isnull().sum()) # gender, enrolled_university, education_level, major_discipline, experience, company_size, company_type, last_new_job\n",
    "# print(test.isnull().sum())\n",
    "# train.describe()\n",
    "# train.describe(include='O')\n",
    "# test.describe(include='O')\n",
    "# train['target'].value_counts() # 0.0: 11517 / 1.0: 3809\n",
    "# print(train.shape, test.shape) # (15326, 14) (3832, 13)\n",
    "\n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# train = train.drop('enrollee_id', axis=1)\n",
    "# test = test.drop('enrollee_id', axis=1)\n",
    "\n",
    "train = train.fillna('X')\n",
    "test = test.fillna('X')\n",
    "\n",
    "# print(train.isnull().sum().sum(), test.isnull().sum().sum())\n",
    "\n",
    "y_train = train.pop('target')\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "# train.shape, test.shape # ë¶ˆì¼ì¹˜\n",
    "\n",
    "df = pd.concat([train, test], axis=0)\n",
    "df_oh = pd.get_dummies(df)\n",
    "train = df_oh.iloc[:len(train)].copy()\n",
    "test = df_oh.iloc[len(train):].copy()\n",
    "\n",
    "# train.shape, test.shape # ì¼ì¹˜\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”©\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "\n",
    "for col in cols_obj :\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "train = df[:len(train)].copy()\n",
    "test = df[len(train):].copy()\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_num = train.select_dtypes(exclude='O').columns\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "train[cols_num] = minmax.fit_transform(train[cols_num])\n",
    "test[cols_num] = minmax.transform(test[cols_num])\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,\n",
    "                                                  y_train,\n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42)\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=5, n_estimators=500)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict_proba(X_val)\n",
    "\n",
    "# print(rf.classes_)\n",
    "# print(y_pred)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred[:,1])\n",
    "print('roc-auc:', roc_auc)\n",
    "\n",
    "## ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±\n",
    "pred = rf.predict_proba(test)\n",
    "result = pd.DataFrame({'pred':pred[:,1]})\n",
    "result.to_csv('new2.csv', index=False)\n",
    "\n",
    "pd.read_csv('new2.csv').head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.select_dtypes(include='O')\n",
    "\n",
    "for col in cols:\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "\n",
    "    if train_set == test_set :\n",
    "        print(col, 'ë™ì¼')\n",
    "    else :\n",
    "        print(col, 'ë™ì¼í•˜ì§€ ì•ŠìŒ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f0971",
   "metadata": {},
   "source": [
    "---\n",
    "#### Q3. ì‹ ìš©ì¹´ë“œ ì‹ ì²­ìì˜ ì±„ë¬´ ë¶ˆì´í–‰ì„ ì˜ˆì¸¡í•˜ì‹œì˜¤.\n",
    "- ì œê³µëœ ë°ì´í„° : `creditcard_train.csv`, `creditcard_test.csv`\n",
    "- ì˜ˆì¸¡í•  ì»¬ëŸ¼ : `STATUS` (0: ì±„ë¬´ ì´í–‰, 1: ì±„ë¬´ ë¶ˆì´í–‰)\n",
    "\n",
    "\n",
    "í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ ë¯¸ë˜ì˜ ì±„ë¬´ ë¶ˆì´í–‰ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“  í›„ ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.\n",
    "\n",
    "\n",
    "ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•œë‹¤.\n",
    "- pred : ì˜ˆì¸¡ê°’ (ì±„ë¬´ ë¶ˆì´í–‰ í™•ë¥ )\n",
    "- ì œì¶œ íŒŒì¼ëª… : `new3.csv`\n",
    "\n",
    "\n",
    "ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ F1 í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d253b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE_GENDER ë™ì¼\n",
      "FLAG_OWN_CAR ë™ì¼\n",
      "FLAG_OWN_REALTY ë™ì¼\n",
      "NAME_INCOME_TYPE ë™ì¼\n",
      "NAME_EDUCATION_TYPE ë™ì¼\n",
      "NAME_FAMILY_STATUS ë™ì¼\n",
      "NAME_HOUSING_TYPE ë™ì¼\n",
      "OCCUPATION_TYPE ë™ì¼í•˜ì§€ ì•ŠìŒ\n",
      "-----------------------\n",
      "[0 1]\n",
      "[0 0 0 ... 0 0 0]\n",
      "f1-score: 0.3241106719367589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7591, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('creditcard_train.csv')\n",
    "test = pd.read_csv('creditcard_test.csv')\n",
    "\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "\n",
    "    if train_set == test_set :\n",
    "        print(col, 'ë™ì¼')\n",
    "    else :\n",
    "        print(col, 'ë™ì¼í•˜ì§€ ì•ŠìŒ')\n",
    "\n",
    "print('-----------------------')\n",
    "\n",
    "## EDA\n",
    "# train.info()\n",
    "# test.info()\n",
    "# train.shape, test.shape # ((25519, 19), (7591, 18))\n",
    "# train.isnull().sum() # OCCUPATION_TYPE \n",
    "# test.isnull().sum()\n",
    "# train['STATUS'].value_counts() # 0: 25085 / 1: 434\n",
    "\n",
    "## ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# train['OCCUPATION_TYPE'].value_counts()\n",
    "train['OCCUPATION_TYPE'] = train['OCCUPATION_TYPE'].fillna(train['OCCUPATION_TYPE'].mode()[0])\n",
    "\n",
    "train = train.drop('ID', axis=1)\n",
    "test = test.drop('ID', axis=1)\n",
    "\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "\n",
    "y_train = train.pop('STATUS')\n",
    "\n",
    "# # ì›-í•« ì¸ì½”ë”©\n",
    "# train = pd.get_dummies(train)\n",
    "# test = pd.get_dummies(test)\n",
    "# # train.shape, test.shape\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”©\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in cols_obj :\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "    \n",
    "# # ìŠ¤ì¼€ì¼ë§ (ê°œì„  x)\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# cols_num = train.select_dtypes(exclude='O').columns\n",
    "\n",
    "# minmax = MinMaxScaler()\n",
    "# train[cols_num] = minmax.fit_transform(train[cols_num])\n",
    "# test[cols_num] = minmax.transform(test[cols_num])\n",
    "\n",
    "## ê²€ì¦ ë°ì´í„° ë¶„í• \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, \n",
    "                                                  y_train, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=0)\n",
    "\n",
    "## ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, n_estimators=500, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "print(rf.classes_)\n",
    "print(y_pred)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print('f1-score:', f1)\n",
    "\n",
    "## ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred})\n",
    "result.to_csv('new3.csv', index=False)\n",
    "\n",
    "pd.read_csv('new3.csv').shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d0547",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
