{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccc42ea",
   "metadata": {},
   "source": [
    "### **🧠 머신러닝 실습 - 이진 분류**\n",
    "#### Q1. 환자의 당뇨병 여부를 예측하시오.\n",
    "- 제공된 데이터 : `diabetes_train.csv`, `diabetes_test.csv`\n",
    "- 예측할 컬럼 : `Outcome` (0: 정상, 1: 당뇨병)\n",
    "\n",
    "\n",
    "학습용 데이터(train)을 이용해 환자의 당뇨병을 예측하는 모델을 만든 후 이를 평가용 데이터(test)에 적용해 얻은 예측값을 다음과 같은 형식의 csv 파일로 생성하시오.\n",
    "\n",
    "\n",
    "제출 파일은 다음 1개의 컬럼을 포함해야 한다.\n",
    "- pred : 예측값 (당뇨병일 확률)\n",
    "- 제출 파일명 : `new.csv`\n",
    "\n",
    "\n",
    "제출한 모델의 성능은 ROC-AUC 평가지표에 따라 채점한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10eb69e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: 0.8234969663541093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(154, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## 데이터 불러오기\n",
    "train = pd.read_csv('diabetes_train.csv')\n",
    "test = pd.read_csv('diabetes_test.csv')\n",
    "\n",
    "## EDA\n",
    "# print(train.shape, test.shape) # ((614, 9), (154, 8))\n",
    "# train.info() # not object\n",
    "# test.info()\n",
    "# train.describe()\n",
    "# print(train.isnull().sum())\n",
    "# print(test.isnull().sum())\n",
    "# print(train['Outcome'].value_counts()) # 0: 403 / 1: 211\n",
    "\n",
    "## 데이터 전처리\n",
    "y_train = train.pop('Outcome')\n",
    "## - 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "train = minmax.fit_transform(train)\n",
    "test = minmax.transform(test)\n",
    "\n",
    "\n",
    "## 검증 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=42)\n",
    "# print(X_train.shape, X_val.shape, y_train.shape, y_val.shape) # (491, 8) (123, 8) (491,) (123,)\n",
    "\n",
    "## 모델 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "rf = RandomForestClassifier(max_depth=5, n_estimators=500, random_state=0)\n",
    "# rf = RandomForestClassifier(random_state=0) # 기본\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict_proba(X_val)\n",
    "# print(rf.classes_)\n",
    "# print(pred)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, pred[:,1])\n",
    "print('roc_auc:', roc_auc)\n",
    "\n",
    "## 예측 및 결과 파일 생성\n",
    "pred = rf.predict_proba(test)\n",
    "result = pd.DataFrame({'pred':pred[:,1]})\n",
    "result.to_csv('new.csv', index=False)\n",
    "\n",
    "pd.read_csv('new.csv').shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa0f6a8",
   "metadata": {},
   "source": [
    "스케일링 전 roc_auc : 0.8167402095973524\n",
    "\n",
    "\n",
    "\n",
    "스케일링 후 roc_auc : 0.8234969663541093\n",
    "\n",
    "\n",
    "**[하이퍼파라미터 튜닝]**\n",
    "- `max_depth` : 트리의 최대 깊이, 과적합 방지, 3~7 정도 적당\n",
    "- `n_estimators` : 트리의 개수, 높을수록 안정적 예측 가능(학습 시간 소요), 200~500 정도 적당\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc35ca7",
   "metadata": {},
   "source": [
    "#### Q2. 새로운 일자리를 찾을지 예측하시오.\n",
    "- 제공된 데이터 : `hr_train.csv`, `hr_test.csv`\n",
    "- 예측할 컬럼 : `target` (0: 새로운 일자리를 찾지 않음, 1: 새로운 일자리를 찾음)\n",
    "\n",
    "\n",
    "학습용 데이터(train)을 이용해 새 일자리를 찾을지 예측하는 모델을 만든 후 이를 평가용 데이터(test)에 적용해 얻은 예측값을 다음과 같은 형식의 csv 파일로 생성하시오.\n",
    "\n",
    "\n",
    "제출 파일은 다음 1개의 컬럼을 포함해야 한다.\n",
    "- pred : 예측값 (이직할 확률)\n",
    "- 제출 파일명 : `new2.csv`\n",
    "\n",
    "\n",
    "제출한 모델의 성능은 ROC-AUC 평가지표에 따라 채점한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8860c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc: 0.7952435945564116\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.394253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.157046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred\n",
       "0  0.234171\n",
       "1  0.394253\n",
       "2  0.411359\n",
       "3  0.140237\n",
       "4  0.157046"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 라이브러리 및 데이터 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('hr_train.csv')\n",
    "test = pd.read_csv('hr_test.csv')\n",
    "\n",
    "## EDA\n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "# print(train.isnull().sum()) # gender, enrolled_university, education_level, major_discipline, experience, company_size, company_type, last_new_job\n",
    "# print(test.isnull().sum())\n",
    "# train.describe()\n",
    "# train.describe(include='O')\n",
    "# test.describe(include='O')\n",
    "# train['target'].value_counts() # 0.0: 11517 / 1.0: 3809\n",
    "# print(train.shape, test.shape) # (15326, 14) (3832, 13)\n",
    "\n",
    "## 데이터 전처리\n",
    "# train = train.drop('enrollee_id', axis=1)\n",
    "# test = test.drop('enrollee_id', axis=1)\n",
    "\n",
    "train = train.fillna('X')\n",
    "test = test.fillna('X')\n",
    "\n",
    "# print(train.isnull().sum().sum(), test.isnull().sum().sum())\n",
    "\n",
    "y_train = train.pop('target')\n",
    "\n",
    "# 원-핫 인코딩\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "# train.shape, test.shape # 불일치\n",
    "\n",
    "df = pd.concat([train, test], axis=0)\n",
    "df_oh = pd.get_dummies(df)\n",
    "train = df_oh.iloc[:len(train)].copy()\n",
    "test = df_oh.iloc[len(train):].copy()\n",
    "\n",
    "# train.shape, test.shape # 일치\n",
    "\n",
    "# 라벨 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "\n",
    "for col in cols_obj :\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "train = df[:len(train)].copy()\n",
    "test = df[len(train):].copy()\n",
    "\n",
    "# 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_num = train.select_dtypes(exclude='O').columns\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "train[cols_num] = minmax.fit_transform(train[cols_num])\n",
    "test[cols_num] = minmax.transform(test[cols_num])\n",
    "\n",
    "## 검증 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,\n",
    "                                                  y_train,\n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42)\n",
    "\n",
    "## 모델 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=5, n_estimators=500)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict_proba(X_val)\n",
    "\n",
    "# print(rf.classes_)\n",
    "# print(y_pred)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred[:,1])\n",
    "print('roc-auc:', roc_auc)\n",
    "\n",
    "## 예측 및 결과 파일 생성\n",
    "pred = rf.predict_proba(test)\n",
    "result = pd.DataFrame({'pred':pred[:,1]})\n",
    "result.to_csv('new2.csv', index=False)\n",
    "\n",
    "pd.read_csv('new2.csv').head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.select_dtypes(include='O')\n",
    "\n",
    "for col in cols:\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "\n",
    "    if train_set == test_set :\n",
    "        print(col, '동일')\n",
    "    else :\n",
    "        print(col, '동일하지 않음')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f0971",
   "metadata": {},
   "source": [
    "---\n",
    "#### Q3. 신용카드 신청자의 채무 불이행을 예측하시오.\n",
    "- 제공된 데이터 : `creditcard_train.csv`, `creditcard_test.csv`\n",
    "- 예측할 컬럼 : `STATUS` (0: 채무 이행, 1: 채무 불이행)\n",
    "\n",
    "\n",
    "학습용 데이터(train)을 이용해 미래의 채무 불이행을 예측하는 모델을 만든 후 이를 평가용 데이터(test)에 적용해 얻은 예측값을 다음과 같은 형식의 csv 파일로 생성하시오.\n",
    "\n",
    "\n",
    "제출 파일은 다음 1개의 컬럼을 포함해야 한다.\n",
    "- pred : 예측값 (채무 불이행 확률)\n",
    "- 제출 파일명 : `new3.csv`\n",
    "\n",
    "\n",
    "제출한 모델의 성능은 F1 평가지표에 따라 채점한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d253b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE_GENDER 동일\n",
      "FLAG_OWN_CAR 동일\n",
      "FLAG_OWN_REALTY 동일\n",
      "NAME_INCOME_TYPE 동일\n",
      "NAME_EDUCATION_TYPE 동일\n",
      "NAME_FAMILY_STATUS 동일\n",
      "NAME_HOUSING_TYPE 동일\n",
      "OCCUPATION_TYPE 동일하지 않음\n",
      "-----------------------\n",
      "[0 1]\n",
      "[0 0 0 ... 0 0 0]\n",
      "f1-score: 0.3241106719367589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7591, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('creditcard_train.csv')\n",
    "test = pd.read_csv('creditcard_test.csv')\n",
    "\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "\n",
    "    if train_set == test_set :\n",
    "        print(col, '동일')\n",
    "    else :\n",
    "        print(col, '동일하지 않음')\n",
    "\n",
    "print('-----------------------')\n",
    "\n",
    "## EDA\n",
    "# train.info()\n",
    "# test.info()\n",
    "# train.shape, test.shape # ((25519, 19), (7591, 18))\n",
    "# train.isnull().sum() # OCCUPATION_TYPE \n",
    "# test.isnull().sum()\n",
    "# train['STATUS'].value_counts() # 0: 25085 / 1: 434\n",
    "\n",
    "## 데이터 전처리\n",
    "# train['OCCUPATION_TYPE'].value_counts()\n",
    "train['OCCUPATION_TYPE'] = train['OCCUPATION_TYPE'].fillna(train['OCCUPATION_TYPE'].mode()[0])\n",
    "\n",
    "train = train.drop('ID', axis=1)\n",
    "test = test.drop('ID', axis=1)\n",
    "\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "\n",
    "y_train = train.pop('STATUS')\n",
    "\n",
    "# # 원-핫 인코딩\n",
    "# train = pd.get_dummies(train)\n",
    "# test = pd.get_dummies(test)\n",
    "# # train.shape, test.shape\n",
    "\n",
    "# 라벨 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in cols_obj :\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "    \n",
    "# # 스케일링 (개선 x)\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# cols_num = train.select_dtypes(exclude='O').columns\n",
    "\n",
    "# minmax = MinMaxScaler()\n",
    "# train[cols_num] = minmax.fit_transform(train[cols_num])\n",
    "# test[cols_num] = minmax.transform(test[cols_num])\n",
    "\n",
    "## 검증 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, \n",
    "                                                  y_train, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=0)\n",
    "\n",
    "## 모델 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, n_estimators=500, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "print(rf.classes_)\n",
    "print(y_pred)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print('f1-score:', f1)\n",
    "\n",
    "## 예측 및 결과 파일 생성\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred})\n",
    "result.to_csv('new3.csv', index=False)\n",
    "\n",
    "pd.read_csv('new3.csv').shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786008c",
   "metadata": {},
   "source": [
    "---\n",
    "### **🧠 머신러닝 실습 - 다중 분류**\n",
    "#### Q1. 은행 정보로 신용 등급을 예측하시오.\n",
    "- 제공된 데이터 : `score_train.csv`, `score_test.csv`\n",
    "- 예측할 컬럼 : `Credit_Score` (Good, Standard, Poor)\n",
    "\n",
    "\n",
    "학습용 데이터(train)을 이용해 신용 등급을 예측하는 모델을 만든 후 이를 평가용 데이터(test)에 적용해 얻은 예측값을 다음과 같은 형식의 csv 파일로 생성하시오.\n",
    "\n",
    "\n",
    "제출 파일은 다음 1개의 컬럼을 포함해야 한다.\n",
    "- pred : 예측값\n",
    "- 제출 파일명 : `new4.csv`\n",
    "\n",
    "\n",
    "제출한 모델의 성능은 F1-macro 평가지표에 따라 채점한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85117751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payment_of_Min_Amount 동일\n",
      "Credit_Mix 동일\n",
      "Payment_Behaviour 동일\n",
      "---------------------\n",
      "['Good' 'Poor' 'Standard']\n",
      "---------------------\n",
      "f1-macro: 0.7006138262986147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1499, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('score_train.csv')\n",
    "test = pd.read_csv('score_test.csv')\n",
    "\n",
    "## EDA\n",
    "# train.head()\n",
    "# train.info()\n",
    "# test.info()\n",
    "# train.isnull().sum()\n",
    "# test.isnull().sum()\n",
    "# print(train.shape, test.shape)\n",
    "# train['Credit_Score'].value_counts()\n",
    "\n",
    "## 데이터 전처리\n",
    "y_train = train.pop('Credit_Score')\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[cols_obj])\n",
    "    test_set = set(test[cols_obj])\n",
    "    \n",
    "    if train_set == test_set :\n",
    "        print(col, '동일')\n",
    "    else :\n",
    "        print(col, '동일하지 않음')\n",
    "print('---------------------')\n",
    "\n",
    "# 원-핫 인코딩\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "train.shape, test.shape\n",
    "\n",
    "# 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_num = train.select_dtypes(exclude='O').columns\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "train[cols_num] = minmax.fit_transform(train[cols_num])\n",
    "test[cols_num] = minmax.transform(test[cols_num])\n",
    "\n",
    "## 검증 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, \n",
    "                                                  y_train, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=0)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
    "\n",
    "## 모델 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "print(rf.classes_)\n",
    "print('---------------------')\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_val, y_pred, average='macro')\n",
    "print('f1-macro:', f1)\n",
    "\n",
    "## 예측 및 결과 파일 생성\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred})\n",
    "result.to_csv('new4.csv', index=False)\n",
    "\n",
    "pd.read_csv('new4.csv').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedabdf9",
   "metadata": {},
   "source": [
    "#### Q2. 주어진 데이터에서 약물의 종류를 예측하시오.\n",
    "- 제공된 데이터 : `drug_train.csv`, `drug_test.csv`\n",
    "- 예측할 컬럼 : `Drug` (DrugY, DrugX, drugA, drugC, drugB)\n",
    "\n",
    "\n",
    "학습용 데이터(train)을 이용해 약물의 종류를 예측하는 모델을 만든 후 이를 평가용 데이터(test)에 적용해 얻은 예측값을 다음과 같은 형식의 csv 파일로 생성하시오.\n",
    "\n",
    "\n",
    "제출 파일은 다음 1개의 컬럼을 포함해야 한다.\n",
    "- pred : 예측값\n",
    "- 제출 파일명 : `new5.csv`\n",
    "\n",
    "\n",
    "제출한 모델의 성능은 f1-macro 평가지표에 따라 채점한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3419fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex 동일\n",
      "BP 동일\n",
      "Cholesterol 동일\n",
      "---------------------------\n",
      "---------------------------\n",
      "f1: 0.9074643874643874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('drug_train.csv')\n",
    "test = pd.read_csv('drug_test.csv')\n",
    "\n",
    "## EDA\n",
    "train.head()\n",
    "train.shape, test.shape # ((100, 6), (100, 5))\n",
    "train.isnull().sum()\n",
    "test.isnull().sum()\n",
    "train.describe()\n",
    "train.describe(include='O')\n",
    "\n",
    "y_train = train.pop('Drug')\n",
    "\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "cols_num = train.select_dtypes(exclude='O').columns\n",
    "\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "    if train_set == test_set :\n",
    "        print(col, '동일')\n",
    "    else :\n",
    "        print(col, '동일하지 않음')\n",
    "\n",
    "print('---------------------------')\n",
    "\n",
    "## 데이터 전처리\n",
    "# 원-핫 인코딩\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "train.shape, test.shape\n",
    "\n",
    "# 라벨 인코딩\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for col in cols_obj : \n",
    "#     le = LabelEncoder()\n",
    "#     train[col] = le.fit_transform(train[col])\n",
    "#     test[col] = le.transform(test[col])\n",
    "\n",
    "## 검증 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "## 모델 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "## 크로스 밸리데이션 활용\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "# rf.fit(X_train, y_train)\n",
    "# y_pred = rf.predict(X_val)\n",
    "# print(rf.classes_)\n",
    "# print(y_pred)\n",
    "print('---------------------------')\n",
    "\n",
    "f1 = cross_val_score(rf, train, y_train, cv=3, scoring='f1_macro')\n",
    "print('f1:', f1.mean())\n",
    "\n",
    "## 예측 및 결과 파일 생성\n",
    "rf.fit(train, y_train)\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred})\n",
    "result.to_csv('new5.csv', index=False)\n",
    "\n",
    "pd.read_csv('new5.csv').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a6d81",
   "metadata": {},
   "source": [
    "#### Q3. 주어진 데이터에서 유리의 종류를 예측하시오.\n",
    "- 제공된 데이터 : `glass_train.csv`, `glass_test.csv`\n",
    "- 예측할 컬럼 : `Type` (1, 2, 3, 4, 5, 6, 7)\n",
    "\n",
    "\n",
    "학습용 데이터(train)을 이용해 유리의 종류를 예측하는 모델을 만든 후 이를 평가용 데이터(test)에 적용해 얻은 예측값을 다음과 같은 형식의 csv 파일로 생성하시오.\n",
    "\n",
    "\n",
    "제출 파일은 다음 1개의 컬럼을 포함해야 한다.\n",
    "- pred : 예측값\n",
    "- 제출 파일명 : `new6.csv`\n",
    "\n",
    "\n",
    "제출한 모델의 성능은 f1-weighted 평가지표에 따라 채점한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc20eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.6507936507936507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(65, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('glass_train.csv')\n",
    "test = pd.read_csv('glass_test.csv')\n",
    "\n",
    "## EDA\n",
    "# train.shape, test.shape # ((149, 10), (65, 9))\n",
    "# train.info()\n",
    "# test.info()\n",
    "# train.isnull().sum()  \n",
    "# test.isnull().sum()\n",
    "# train['Type'].value_counts()\n",
    "# train.describe()\n",
    "\n",
    "## 데이터 전처리\n",
    "y_train = train.pop('Type')\n",
    "\n",
    "# 원-핫 인코딩\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "# train.shape, test.shape\n",
    "\n",
    "# 라벨 인코딩\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# df = pd.concat([train, test])\n",
    "\n",
    "# cols = train.columns\n",
    "# for col in cols :\n",
    "#     le = LabelEncoder()\n",
    "#     df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# train = df.iloc[:len(train)]\n",
    "# test = df.iloc[len(train):]\n",
    "\n",
    "\n",
    "## 검증 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "## 모델 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=5, n_estimators=700)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "# print(rf.classes_)\n",
    "# print(y_pred)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "print('f1:', f1)\n",
    "\n",
    "## 예측 및 결과 파일 생성하기\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred})\n",
    "result.to_csv('new6.csv', index=False)\n",
    "\n",
    "pd.read_csv('new6.csv').shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda6db6f",
   "metadata": {},
   "source": [
    "---\n",
    "### **🧠 머신러닝 실습 - 회귀**\n",
    "#### Q1. 항공권 티켓 가격을 예측하시오.\n",
    "- 제공된 데이터 : `flight_train.csv`, `flight_test.csv`\n",
    "- 예측할 컬럼 : `price`\n",
    "\n",
    "\n",
    "학습용 데이터(train)을 이용해 티켓 가격을 예측하는 모델을 만든 후 이를 평가용 데이터(test)에 적용해 얻은 예측값을 다음과 같은 형식의 csv 파일로 생성하시오.\n",
    "\n",
    "\n",
    "제출 파일은 다음 1개의 컬럼을 포함해야 한다.\n",
    "- pred : 예측값 (가격)\n",
    "- 제출 파일명 : `new7.csv`\n",
    "\n",
    "\n",
    "제출한 모델의 성능은 RMSE 평가지표에 따라 채점한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b22eeca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 카테고리 동일 여부 ------\n",
      "airline 동일\n",
      "flight 동일하지 않음\n",
      "source_city 동일\n",
      "departure_time 동일\n",
      "stops 동일\n",
      "arrival_time 동일\n",
      "destination_city 동일\n",
      "class 동일\n",
      "\n",
      "------ RMSE SCORE ------\n",
      "rmse: 3674.8958942154045\n",
      "\n",
      "------ 최종 결과 파일 확인 ------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4502, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('flight_train.csv')\n",
    "test = pd.read_csv('flight_test.csv')\n",
    "\n",
    "## EDA\n",
    "# train.info()\n",
    "# test.info()\n",
    "# print(train.shape, test.shape) # (10505, 11) (4502, 10)\n",
    "# train.describe()\n",
    "# train.describe(include='O')\n",
    "# train.isnull().sum()\n",
    "# test.isnull().sum()\n",
    "\n",
    "print ('------ 카테고리 동일 여부 ------')\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "    if train_set == test_set :\n",
    "        print(col, '동일')\n",
    "    else :\n",
    "        print(col, '동일하지 않음')\n",
    "        \n",
    "## 데이터 전처리\n",
    "y_train = train.pop('price')\n",
    "\n",
    "train['new_flight'] = train['flight'].str.split('-').str[1].astype(int)\n",
    "test['new_flight'] = test['flight'].str.split('-').str[1].astype(int)\n",
    "\n",
    "train = train.drop('flight', axis=1)\n",
    "test = test.drop('flight', axis=1)\n",
    "\n",
    "# 원-핫 인코딩\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "# print(train.shape, train_oh.shape, test.shape, test_oh.shape)\n",
    "\n",
    "# df = pd.concat([train, test], axis=0)\n",
    "# df = pd.get_dummies(df)\n",
    "# train = df[:len(train)]\n",
    "# test = df[len(train):]\n",
    "# train.shape, test.shape\n",
    "\n",
    "# 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cols_num = train.select_dtypes(exclude='O').columns\n",
    "rb = StandardScaler()\n",
    "train[cols_num] = rb.fit_transform(train[cols_num])\n",
    "test[cols_num] = rb.transform(test[cols_num])\n",
    "\n",
    "\n",
    "## 검증 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=0)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
    "\n",
    "## 모델 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, max_depth=20, n_estimators=200)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "rmse = root_mean_squared_error(y_val, y_pred)\n",
    "print ('\\n------ RMSE SCORE ------')\n",
    "print('rmse:', rmse)  \n",
    "\n",
    "## 예측 및 결과 파일 생성\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred}).to_csv('new7.csv', index=False)\n",
    "\n",
    "print ('\\n------ 최종 결과 파일 확인 ------')\n",
    "pd.read_csv('new7.csv').shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75544460",
   "metadata": {},
   "source": [
    "#### Q2. 노트북 가격을 예측하시오.\n",
    "- 제공된 데이터 : `laptop_train.csv`, `laptop_test.csv`\n",
    "- 예측할 컬럼 : `Price`\n",
    "\n",
    "\n",
    "학습용 데이터(train)을 이용해 노트북 가격을 예측하는 모델을 만든 후 이를 평가용 데이터(test)에 적용해 얻은 예측값을 다음과 같은 형식의 csv 파일로 생성하시오.\n",
    "\n",
    "\n",
    "제출 파일은 다음 1개의 컬럼을 포함해야 한다.\n",
    "- pred : 예측값 (가격)\n",
    "- 제출 파일명 : `new8.csv`\n",
    "\n",
    "\n",
    "제출한 모델의 성능은 R²(결정계수) 평가지표에 따라 채점한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6dcab750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 91 entries, 0 to 90\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Brand               91 non-null     object \n",
      " 1   Model               82 non-null     object \n",
      " 2   Series              55 non-null     object \n",
      " 3   Processor           86 non-null     object \n",
      " 4   Processor_Gen       86 non-null     object \n",
      " 5   RAM                 85 non-null     float64\n",
      " 6   Hard_Disk_Capacity  85 non-null     object \n",
      " 7   OS                  85 non-null     object \n",
      " 8   Rating              91 non-null     float64\n",
      " 9   Price               91 non-null     int64  \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 7.2+ KB\n",
      "------ 카테고리 동일 여부 ------\n",
      "Brand 동일하지 않음\n",
      "Processor 동일하지 않음\n",
      "Processor_Gen 동일하지 않음\n",
      "Hard_Disk_Capacity 동일하지 않음\n",
      "OS 동일하지 않음\n",
      "\n",
      "------ R² SCORE ------\n",
      "R²: 0.8059084005677305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joajo\\AppData\\Local\\Temp\\ipykernel_4168\\2304860439.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[cols_num] = scaler.fit_transform(train[cols_num])\n",
      "C:\\Users\\joajo\\AppData\\Local\\Temp\\ipykernel_4168\\2304860439.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[cols_num] = scaler.transform(test[cols_num])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('laptop_train.csv')\n",
    "test = pd.read_csv('laptop_test.csv')\n",
    "\n",
    "## EDA\n",
    "train.info()\n",
    "train.isnull().sum()\n",
    "test.isnull().sum()\n",
    "\n",
    "train = train.drop('Model', axis=1)\n",
    "test = test.drop('Model', axis=1)\n",
    "train = train.drop('Series', axis=1)\n",
    "test = test.drop('Series', axis=1)\n",
    "\n",
    "print ('------ 카테고리 동일 여부 ------')\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "    if train_set == test_set :\n",
    "        print(col, '동일')\n",
    "    else :\n",
    "        print(col, '동일하지 않음')\n",
    "        \n",
    "# train.describe()    \n",
    "# train.describe(include='O')\n",
    "\n",
    "## 데이터 전처리\n",
    "y_train = train.pop('Price')\n",
    "\n",
    "# 결측값 처리\n",
    "train[cols_obj] = train[cols_obj].fillna('X')\n",
    "test[cols_obj] = test[cols_obj].fillna('X')\n",
    "\n",
    "train['RAM'] = train['RAM'].fillna(train['RAM'].mode()[0])\n",
    "test['RAM'] = test['RAM'].fillna(test['RAM'].mode()[0])\n",
    "\n",
    "# 원-핫 인코딩\n",
    "# train_oh = pd.get_dummies(train)\n",
    "# test_oh = pd.get_dummies(test)\n",
    "# train.shape, train_oh.shape, test.shape, test_oh.shape\n",
    "df = pd.concat([train, test])\n",
    "df_oh = pd.get_dummies(df)\n",
    "train = df_oh[:len(train)]\n",
    "test = df_oh[len(train):]\n",
    "# train.shape, train_oh.shape, test.shape, test_oh.shape\n",
    "\n",
    "# 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cols_num = train.select_dtypes(exclude='O').columns\n",
    "scaler = StandardScaler()\n",
    "train[cols_num] = scaler.fit_transform(train[cols_num])\n",
    "test[cols_num] = scaler.transform(test[cols_num])\n",
    "\n",
    "\n",
    "## 검증 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "## 모델 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print ('\\n------ R² SCORE ------')\n",
    "print('R²:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e592ee5b",
   "metadata": {},
   "source": [
    "#### Q3. 노트북 가격을 예측하시오.\n",
    "- 제공된 데이터 : `car_train.csv`, `car_test.csv`\n",
    "- 예측할 컬럼 : `Price`\n",
    "\n",
    "\n",
    "학습용 데이터(train)을 이용해 중고차 가격을 예측하는 모델을 만든 후 이를 평가용 데이터(test)에 적용해 얻은 예측값을 다음과 같은 형식의 csv 파일로 생성하시오.\n",
    "\n",
    "\n",
    "제출 파일은 다음 1개의 컬럼을 포함해야 한다.\n",
    "- pred : 예측값 (가격)\n",
    "- 제출 파일명 : `new9.csv`\n",
    "\n",
    "\n",
    "제출한 모델의 성능은 RMSLE 평가지표에 따라 채점한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a08e8407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 카테고리 동일 여부 ------\n",
      "Levy 동일하지 않음\n",
      "Manufacturer 동일하지 않음\n",
      "Model 동일하지 않음\n",
      "Category 동일\n",
      "Leather interior 동일\n",
      "Fuel type 동일하지 않음\n",
      "Engine volume 동일하지 않음\n",
      "Mileage 동일하지 않음\n",
      "Gear box type 동일\n",
      "Drive wheels 동일\n",
      "Doors 동일\n",
      "Wheel 동일\n",
      "Color 동일\n",
      "\n",
      "------ RMSLE SCORE ------\n",
      "RMSLE: 1.0822004244243006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40019.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10820.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16399.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69105.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47603.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred\n",
       "0  40019.835\n",
       "1  10820.880\n",
       "2  16399.925\n",
       "3  69105.440\n",
       "4  47603.045"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('car_train.csv')\n",
    "test = pd.read_csv('car_test.csv')\n",
    "\n",
    "## EDA\n",
    "# train.info()\n",
    "# train.isnull().sum()\n",
    "# test.isnull().sum()\n",
    "# train.describe()\n",
    "# train.describe(include='O')\n",
    "# train.shape, test.shape # ((6732, 17), (5772, 16))\n",
    "\n",
    "print ('------ 카테고리 동일 여부 ------')\n",
    "cols_obj = train.select_dtypes(include='O').columns\n",
    "for col in cols_obj :\n",
    "    train_set = set(train[col])\n",
    "    test_set = set(test[col])\n",
    "    if train_set == test_set :\n",
    "        print(col, '동일')\n",
    "    else :\n",
    "        print(col, '동일하지 않음')\n",
    "        \n",
    "## 데이터 전처리\n",
    "y_train = train.pop('Price')\n",
    "\n",
    "train['Turbo'] = train['Engine volume'].str.contains('Turbo').astype(int)\n",
    "test['Turbo'] = test['Engine volume'].str.contains('Turbo').astype(int)\n",
    "\n",
    "train['Engine volume'] = train['Engine volume'].str.replace('Turbo', '').astype(float)\n",
    "test['Engine volume'] = test['Engine volume'].str.replace('Turbo', '').astype(float)\n",
    "\n",
    "train['Mileage'] = train['Mileage'].str.split().str[0].astype(int)\n",
    "test['Mileage'] = test['Mileage'].str.split().str[0].astype(int)\n",
    "\n",
    "# # 스케일링\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# cols_num = train.select_dtypes(exclude='O').columns\n",
    "# scaler = RobustScaler()\n",
    "# train[cols_num] = scaler.fit_transform(train[cols_num])\n",
    "# test[cols_num] = scaler.transform(test[cols_num])\n",
    "\n",
    "# 원-핫 인코딩\n",
    "# df = pd.concat([train, test])\n",
    "# df_oh = pd.get_dummies(df)\n",
    "# train_oh = df_oh.iloc[:len(train)]\n",
    "# test_oh = df_oh.iloc[len(train):]\n",
    "# print(train.shape, train_oh.shape, test.shape, test_oh.shape)\n",
    "\n",
    "# 라벨 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.concat([train, test])\n",
    "for col in cols_obj :\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "train = df.iloc[:len(train)]\n",
    "test = df.iloc[len(train):]\n",
    "    \n",
    "# print(train.shape, test.shape)\n",
    "\n",
    "## 검증 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "## 모델 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, n_estimators=200)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "rmsle = root_mean_squared_log_error(y_val, y_pred)\n",
    "print ('\\n------ RMSLE SCORE ------')\n",
    "print('RMSLE:', rmsle)\n",
    "\n",
    "# 예측 및 결과 파일 생성\n",
    "pred = rf.predict(test)\n",
    "result = pd.DataFrame({'pred':pred}).to_csv('new9.csv', index=False)\n",
    "pd.read_csv('new9.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6780e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
